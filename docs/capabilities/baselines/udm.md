# ðŸ§­ Universal Diagnostic Model (UDM) â€” v2 (0â€“4 scale)
*A vendorâ€‘neutral baseline describing how intelligent Ops/Observability systems **detect, enrich, correlate, explain (RCA), and recommend/remediate** incidents â€” with verifiable evidence.*

**Last updated:** 2025-10-12T12:28:58Z

---

## What changed in v2
- **Maturity scale normalized to 0â€“4** (was 0â€“4/0â€“5 across sources). Clear **acceptance gates** per level.
- **Precise phase names**: Signal Detection Â· Context Enrichment Â· Event Correlation & Classification Â· Root Cause Analysis Â· Recommendation/Remediation.
- **Atlas alignment**: Tokenâ†’numeric mapping for the Atlas **ðŸ” Diagnostics** capability.
- **Operational metrics**: TTFC/TTRC, Verifiedâ€‘RCA rate, falseâ€‘positive rate added as nonâ€‘functional targets.
- **Exports**: Scorecard CSV and machineâ€‘readable rubric JSON.

---

## âš™ï¸ Five Diagnostic Phases
| # | Phase | Definition | Typical Data | Expected Capability |
|---:|---|---|---|---|
| **1** | **Signal Detection** | Identify anomalies or deviations from expected behavior | Metrics (CPU/latency/errors), logs, traces, alerts | Thresholds, anomaly detectors, driftâ€‘aware baselines; capture detection reason & thresholds |
| **2** | **Context Enrichment** | Link signals with entities, ownership, deploy/change context | Service maps, k8s/CMDB, deploy metadata | Stable IDs, dependency graph, change/owner joins, SLO context |
| **3** | **Event Correlation & Classification** | Group related signals and classify the probable domain/cause family | Multiâ€‘signal events across time windows | Correlation windows, clustering/causal hints, changeâ€‘aware grouping |
| **4** | **Root Cause Analysis (RCA)** | Produce a **testable hypothesis** explaining *why* with evidence | Enriched telemetry + historical baselines + change diffs | Structured hypothesis + verification plan; confidence; negative evidence considered |
| **5** | **Recommendation / Remediation** | Propose (or execute under guardrails) a mitigation with verification | Runbooks, IaC diffs, workflows | Riskâ€‘aware plan, preflight checks, approvals; rollback & postâ€‘verify steps |

---

## ðŸ§© UDM Maturity Scale (0â€“4)

| Level | Label | Acceptance (must satisfy this level **and** all lower levels) |
|---:|---|---|
| **0** | **None** | No diagnostics beyond raw alerts/logs; no context; no evidence export. |
| **1** | **Reactive** | L1 detection: manual/threshold alerts; minimal labeling; adâ€‘hoc triage notes. |
| **2** | **Correlated** | L2 detection + **multiâ€‘signal correlation or ruleâ€‘based classification**; entity/service mapping; links to evidence (queries/logs/traces). |
| **3** | **Intelligent** | L3 adds **structured RCA** with **verification steps** (counterâ€‘tests), confidence scoring, change awareness, and **explainable evidence** (permalinks/queries included). |
| **4** | **Autonomous** | L4 adds **causal reasoning/graphs**, **automated counterâ€‘tests**, earlyâ€‘finalize on high confidence, and **guardrailed remediation** (approvals/rollback), with tracked quality metrics (Verifiedâ€‘RCA rate, FP rate). |

> **Gating rule:** A productâ€™s **UDM level** is the **highest level** whose acceptance gates (and all below) are met. Any missing gate caps the level.

---

## ðŸ”Ž Perâ€‘phase expectations by level (condensed)

### 1) Signal Detection
- **L0:** Raw alerts or manual observation only.  
- **L1:** Static thresholds; alert definitions exist; detection reason/threshold captured.  
- **L2:** **Anomaly detection** or pattern mining; crossâ€‘signal awareness.  
- **L3:** Baselines per entity/SLO; changeâ€‘aware detectors reduce noise.  
- **L4:** Drift detection, adaptive thresholds; quality metrics (precision/recall) tracked.

### 2) Context Enrichment
- **L0:** No stable IDs; no owners.  
- **L1:** Basic labels (service/env).  
- **L2:** **Entity/owner mapping**; dependency edges; deploy metadata attached.  
- **L3:** SLO context + recent **change** joins; impact radius estimated.  
- **L4:** Versioned topology; outâ€‘ofâ€‘date context flagged; lineage kept.

### 3) Event Correlation & Classification
- **L0:** Each alert stands alone.  
- **L1:** Manual grouping.  
- **L2:** **Timeâ€‘window correlation**; domain tagging (network/db/app).  
- **L3:** Multiâ€‘signal clustering + **changeâ€‘aware grouping**; duplicate suppression.  
- **L4:** Causal graph with scored edges; nearâ€‘duplicate incidents merged automatically.

### 4) Root Cause Analysis (RCA)
- **L0:** No causal statement.  
- **L1:** Freeâ€‘text guess; no tests.  
- **L2:** Heuristic RCA with links to **raw evidence**.  
- **L3:** **Structured hypothesis** (entity/change), **verification plan** with counterâ€‘tests, confidence value, and negative evidence.  
- **L4:** **Causal/graphâ€‘based** RCA; automated counterâ€‘tests; **early finalize** on high confidence; falseâ€‘positive rate tracked.

### 5) Recommendation / Remediation
- **L0:** None.  
- **L1:** Human advice only.  
- **L2:** Runbook suggestions with evidence links.  
- **L3:** **Structured plan**: preflight checks, risk notes, postâ€‘verify steps.  
- **L4:** **Guardrailed automation**: approvals, drift checks, **rollback plan**, closedâ€‘loop verification and audit.

---

## âœ… Feature Requirements (FR) & Acceptance Criteria (AC)

**F1. Detection** â€” Ingest metrics/logs/traces; configurable thresholds and anomaly detectors; store **detection reason** (rule, threshold, model).  
**AC:** A sample incident shows detection metadata (why/where), reproducible by reâ€‘running the query or rule.

**F2. Context** â€” Maintain entity IDs, owners, dependency/impact edges, deploy/change metadata, SLO context.  
**AC:** Given an incident, the system lists affected entity, owner, last deploy/change, and SLO window.

**F3. Correlation** â€” Group events across a window; label domain; suppress duplicates; link correlation evidence.  
**AC:** Incident record shows the grouped alerts with grouping rationale and time bounds.

**F4. RCA** â€” Emit **hypotheses[]** with fields: `entity`, `suspected_change`, `evidence_refs[]`, `counter_tests[]`, `confidence` (0â€“1).  
**AC:** At least one counterâ€‘test runs and is linkable; negative evidence reduces confidence.

**F5. Recommendation/Remediation** â€” Produce a plan with steps, **preflight checks**, required approvals, and **postâ€‘verify**.  
**AC:** Plan lists commands/runbooks or PRs; on execution, verification results are attached; rollback path is present.

---

## ðŸ“ˆ Nonâ€‘functional Targets (diagnostic quality & speed)

- **TTFC** (timeâ€‘toâ€‘firstâ€‘clue) P50 â‰¤ **60â€¯s**, P95 â‰¤ **3â€¯min** on standard incident set.  
- **TTRC** (timeâ€‘toâ€‘rootâ€‘cause) P50 â‰¤ **10â€¯min**, P95 â‰¤ **30â€¯min** (for contained scope).  
- **Verifiedâ€‘RCA rate** â‰¥ **80%** on curated set; **falseâ€‘positive rate** tracked and trending down.  
- **Explainability**: each RCA contains **evidence permalinks**; queries are reâ€‘runnable.  
- **Stability**: detectors tolerant to data gaps; safeguards against alert storms.

---

## ðŸ” Atlas alignment (ðŸ” Diagnostics token â†’ UDM level)

| Atlas token | UDM level |
|---|---:|
| **N/L** | **0** |
| **P/L** | **1** |
| **P/M** | **2** |
| **Y/M** | **3** |
| **Y/H** | **4** |

> Use this to convert Atlas table entries into UDMâ€™s 0â€“4 for composite scoring.

---

## ðŸ§  Neutral Diagnostic Event (JSON example)

```json
{
  "diagnostic_event": {
    "id": "uuid",
    "timestamp": "2025-10-08T15:00:00Z",
    "phase": "root_cause",
    "signal": { "metric": "latency_p95", "value": 560, "threshold": 200 },
    "context": { "service": "api-gateway", "node": "node-12", "region": "eu-west" },
    "correlation_group": "incident-4431",
    "root_cause": { "hypothesis": "deployment rollback failed", "confidence": 0.87 },
    "evidence_refs": ["grafana://...","loki://...","change://deploy/abc123"],
    "counter_tests": ["promql://increase(errors_total,5m)","logql://kubernetes.container.name=api-gateway"],
    "recommendation": { "action": "redeploy previous version", "automatable": true, "requires_approval": true }
  }
}
```

---

## ðŸ” Comparison Template (vs. UDM)

| Platform | Signal Detection | Context Enrichment | Event Correlation | Root Cause Analysis | Recommendation/Remediation | **Overall UDM Level (0â€“4)** |
|---|---|---|---|---|---|---|
| **Your Platform** |  |  |  |  |  |  |
| Competitor A |  |  |  |  |  |  |
| Competitor B |  |  |  |  |  |  |

> Keep evidence links (alert rules, queries, grouped incident records, RCA plans, runbooks) for every âœ“.

---

## ðŸ“ Conformance Checklist

- Detection records include **why** (rule/model/threshold) and are reproducible.  
- Entity/owner/deploy/change context resolvable for each incident.  
- Correlation shows window/rationale and suppresses duplicates.  
- RCA includes **structured hypothesis**, **counterâ€‘tests**, **confidence**, and **negative evidence** handling.  
- Recommendations include **preflight**, **approvals**, **postâ€‘verify**, and **rollback**.  
- Evidence links are permalinks; raw queries/logs are accessible.  
- Quality metrics (Verifiedâ€‘RCA rate, FP rate) are tracked and reported.

---

## ðŸ“Š Suggested KPIs for bakeâ€‘offs (diagnostics)

- **TTFC/TTRC** distribution on a fixed incident corpus.  
- **Verifiedâ€‘RCA rate** and **falseâ€‘positive rate**.  
- **Correlation quality**: % incidents with correct grouping; duplicate suppression ratio.  
- **Explainability**: % RCAs with runnable queries/logs attached.  
- **Actionability**: % incidents with a safe, approved next step.

---

## ðŸ“Š Ratings â€” Current Platforms (UDM v2)

| Platform | UDM Level |
|---|---:|
| Atlassian â€“ Rovo Dev | 2 |
| AWS â€“ Strands SDK | 1 |
| Cisco â€“ Splunk AI Agents (AgenticOps) | 4 |
| Databricks â€“ Agent Bricks | 3 |
| Datadog â€“ Bits AI SRE | 4 |
| Dataiku â€“ AI Agents | 4 |
| DuploCloud â€“ AI Help Desk | 4 |
| Dynatrace â€“ Davis AI | 4 |
| Elastic â€“ AI Assistant for Observability | 2 |
| GitHub â€“ Copilot | 1 |
| Google â€“ Vertex AI Agent Builder | 1 |
| IBM â€“ AskIAM | 3 |
| JFrog â€“ Project Fly | 2 |
| Solo.io â€“ Kagent | 3 |

> Levels reflect the strict UDM v2 gating rules (evidenceâ€‘backed RCA, counterâ€‘tests, change awareness, and governed remediation).

---

## ðŸ§¾ Platform Notes â€” Evidenceâ€‘backed summaries

### Atlassian â€“ Rovo Dev â€” **UDM 2**
- **Signal Detection:** Reactive; relies on Atlassian alerts (Opsgenie/Compass); no native anomaly detection.  
- **Context Enrichment:** Uses Teamwork Graph to pull commits, issues, docs for a target service.  
- **Event Correlation & Classification:** Light correlation via graph lookups; no multiâ€‘signal causation.  
- **Root Cause Analysis:** Smart search across Atlassian data; identifies likely causes from history, not raw telemetry.  
- **Recommendation/Remediation:** Suggests runbooks/docs; can open PRs/tickets; no autonomous fixes.

### AWS â€“ Strands SDK â€” **UDM 1**
- **Signal Detection:** None by default; developers must wire to CloudWatch or alerts.  
- **Context Enrichment:** Tooling available, but correlation logic is custom to each agent.  
- **Event Correlation & Classification:** No builtâ€‘in engine; depends on prompts/code.  
- **Root Cause Analysis:** LLMâ€‘driven heuristics only as implemented; accuracy varies.  
- **Recommendation/Remediation:** Actions possible via tools; suggestions are unverified unless you add checks.

### Cisco â€“ Splunk AI Agents (AgenticOps) â€” **UDM 4**
- **Signal Detection:** Continuous multiâ€‘domain telemetry with dynamic baselines; predictive alerting; Event iQ noise reduction.  
- **Context Enrichment:** Crossâ€‘domain enrichment (network â†” app â†” infra) with ITSI episodes.  
- **Event Correlation & Classification:** Automatic episode correlation & dedup; prioritized incidents.  
- **Root Cause Analysis:** Causal algorithms pinpoint probable root cause with evidence & timeline.  
- **Recommendation/Remediation:** Actionable recommendations & optional automation via runbooks/integrations.

### Databricks â€“ Agent Bricks â€” **UDM 3**
- **Signal Detection:** Triggered by jobs/model drift; no general prod monitoring outâ€‘ofâ€‘box.  
- **Context Enrichment:** Rich context from Lakehouse (lineage, MLflow), strong data joins.  
- **Event Correlation & Classification:** Good in data/ML domain; relies on implementation for breadth.  
- **Root Cause Analysis:** Multiâ€‘step SQL/ML analyses across curated data when coded.  
- **Recommendation/Remediation:** Can run notebooks/workflows; typically humanâ€‘approved.

### Datadog â€“ Bits AI SRE â€” **UDM 4**
- **Signal Detection:** Launches investigations on monitor alerts; groups related alerts to reduce noise.  
- **Context Enrichment:** Pulls APM, infra, logs, deploys, runbooks; builds incident timeline.  
- **Event Correlation & Classification:** Multiâ€‘hypothesis testing & consolidation into one incident.  
- **Root Cause Analysis:** Rapid, evidenceâ€‘linked RCA with charts, logs, traces.  
- **Recommendation/Remediation:** Prescriptive steps & comms; humanâ€‘inâ€‘theâ€‘loop for execution.

### Dataiku â€“ AI Agents â€” **UDM 4**
- **Signal Detection:** Anomaly triggers in pipelines/metrics; jobs & KPI thresholds.  
- **Context Enrichment:** Business context, curated datasets, model metadata.  
- **Event Correlation & Classification:** Crossâ€‘dataset analyses; topicâ€‘driven classification.  
- **Root Cause Analysis:** Explains drivers (e.g., churn/revenue) with traceable data.  
- **Recommendation/Remediation:** Suggests actions; can trigger pipelines under governance.

### DuploCloud â€“ AI Help Desk â€” **UDM 4**
- **Signal Detection:** Userâ€‘driven & systemâ€‘driven ticketing; ties to platform monitors.  
- **Context Enrichment:** Deep context of cloud config & live state via embedded terminal.  
- **Event Correlation & Classification:** Recognizes known patterns across k8s/network/permissions.  
- **Root Cause Analysis:** Interactive verification by running safe commands; fast isolation.  
- **Recommendation/Remediation:** AIâ€‘suggested commands; oneâ€‘click approved fixes with guardrails.

### Dynatrace â€“ Davis AI â€” **UDM 4**
- **Signal Detection:** Realâ€‘time anomalies with seasonal baselines; single Problem event.  
- **Context Enrichment:** Smartscape topology; business impact (RUM/SLO).  
- **Event Correlation & Classification:** Automatic causation across stack; deduped problem context.  
- **Root Cause Analysis:** Causal AI pinpoints root process/service; explains evidence.  
- **Recommendation/Remediation:** Runbook suggestions & automation engine integrations.

### Elastic â€“ AI Assistant for Observability â€” **UDM 2**
- **Signal Detection:** Assistive; piggybacks on Elastic alerts/ML jobs.  
- **Context Enrichment:** Fast log/trace explanations within Kibana context.  
- **Event Correlation & Classification:** Userâ€‘steered queries across logs/metrics/traces.  
- **Root Cause Analysis:** Great for log triage; limited multiâ€‘system causation.  
- **Recommendation/Remediation:** Light guidance; no autonomous actions.

### GitHub â€“ Copilot â€” **UDM 1**
- **Signal Detection:** None in prod; focused on code/tests in dev.  
- **Context Enrichment:** Understands repo/test context; no ops telemetry.  
- **Event Correlation & Classification:** N/A for ops; helps interpret build logs.  
- **Root Cause Analysis:** Explains code/test failures; not system incidents.  
- **Recommendation/Remediation:** Generates code/config fixes after human diagnosis.

### Google â€“ Vertex AI Agent Builder â€” **UDM 1**
- **Signal Detection:** None outâ€‘ofâ€‘box; flows trigger via intents/webhooks.  
- **Context Enrichment:** Developerâ€‘defined; can fetch metrics via tools.  
- **Event Correlation & Classification:** Scripted logic; no generic engine.  
- **Root Cause Analysis:** Decisionâ€‘tree style unless extended.  
- **Recommendation/Remediation:** Can call tools; governed by custom flows.

### IBM â€“ AskIAM â€” **UDM 3**
- **Signal Detection:** Detects IAM issues (missing roles/SOD conflicts) on queries.  
- **Context Enrichment:** Unifies usersâ†”rolesâ†”apps; pulls login/audit traces.  
- **Event Correlation & Classification:** Deterministic policy reasoning across identity graph.  
- **Root Cause Analysis:** Explains â€˜why/why notâ€™ access with full chain of evidence.  
- **Recommendation/Remediation:** Initiates revoke/grant with approvals; governed changes.

### JFrog â€“ Project Fly â€” **UDM 2**
- **Signal Detection:** CI/CD failure events; artifact policy blocks.  
- **Context Enrichment:** Artifact metadata, Xray findings, repo context.  
- **Event Correlation & Classification:** Maps build failures to deps/repos.  
- **Root Cause Analysis:** Pinpoints failing step/dependency; limited beyond pipeline.  
- **Recommendation/Remediation:** Suggests fixes; automates routine CI tasks.

### Solo.io â€“ Kagent â€” **UDM 3**
- **Signal Detection:** K8s/serviceâ€‘mesh events (crashloops, 5xx, policy blocks).  
- **Context Enrichment:** K8s objects, YAML, mesh telemetry, network policies.  
- **Event Correlation & Classification:** Links config â†” runtime failures.  
- **Root Cause Analysis:** K8s expert checks (deploys, policies, routing).  
- **Recommendation/Remediation:** Proposes YAML patches/commands; optional apply with RBAC.

---

## ðŸ§© Summary (what the ratings say)
- **LevelÂ 4 (Autonomous):** Cisco/Splunk, Datadog, Dataiku, DuploCloud, Dynatrace â€” deliver multiâ€‘signal detection, explainable RCA with evidence, and **guardrailed remediation**.  
- **LevelÂ 3 (Intelligent):** Databricks, Solo.io, IBM AskIAM â€” strong structured RCA in their domains; remediation is governed but not fully automated across all useâ€‘cases.  
- **LevelÂ 2 (Correlated):** Atlassian, Elastic, JFrog â€” correlate and guide investigations; RCA is heuristic; remediation remains manual.  
- **LevelÂ 1 (Reactive):** AWS Strands, GitHub Copilot, Google Vertex â€” frameworks/assistants that require custom wiring for diagnostics.  
- **Key gates failing at lower levels:** lack of **evidenceâ€‘linked RCA** and **counterâ€‘tests**, limited **change awareness**, and absence of **guardrailed remediation with rollback**.
